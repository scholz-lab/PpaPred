{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b5538c-c780-4848-9d27-e2079b7f5f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch, FancyArrowPatch\n",
    "from matplotlib import colors\n",
    "import logging\n",
    "import yaml\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats.contingency import crosstab\n",
    "import networkx as nx\n",
    "from matplotlib.lines import Line2D\n",
    "import umap\n",
    "import itertools\n",
    "import scipy\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "from functions.load_model import load_tolist\n",
    "import functions.visualise as vis\n",
    "import functions.process as proc\n",
    "from functions.io import setup_logger, makedir\n",
    "from functions import FeatureEngine\n",
    "from numba import jit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf8ffb-4c80-4ace-a5b2-426b3ebde26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padtoequalsize(arr1,arr2, dimstocompare = [-1]):\n",
    "    arr1_shape = arr1.shape\n",
    "    arr2_shape = arr2.shape\n",
    "    arr1_pad_template = ([(0,0),]*len(arr1_shape))\n",
    "    arr2_pad_template = ([(0,0),]*len(arr2_shape))\n",
    "    for d in dimstocompare:\n",
    "        pad_size = arr1_shape[d] - arr2_shape[d]\n",
    "        arr1_pad_template = ([(0,0),]*len(arr1_shape))\n",
    "        arr2_pad_template = ([(0,0),]*len(arr2_shape))\n",
    "        arr1_pad_template[d] = (0,abs(pad_size))\n",
    "        arr2_pad_template[d] = (0,pad_size)\n",
    "        if pad_size > 0:\n",
    "            arr2 = np.pad(arr2, arr2_pad_template,'constant', constant_values=np.nan)\n",
    "        if pad_size < 0:\n",
    "            arr1 = np.pad(arr1, arr1_pad_template,'constant', constant_values=np.nan)\n",
    "    return arr1, arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18efb6f1-ab9d-4f9b-a4ec-50a1e27fd49c",
   "metadata": {},
   "source": [
    "Please provide where your files are stored and where you would like your data to be saved in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a3bd5-29bf-44e3-bbe5-231912f5022c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datestr = time.strftime(\"%Y%m%d-%HH%MM\")\n",
    "inpath = \"/gpfs/soma_fs/scratch/src/boeger/PpaPred_eren\" \n",
    "#inpath = '/gpfs/soma_fs/scratch/src/boeger/data_roca'\n",
    "\n",
    "inpath_pattern = ['bac_data']\n",
    "inpath_with_subfolders = True\n",
    "\n",
    "WT_ordering = [0,1,2,3,4,5,6,7]#False#[1., 0., 2., 6., 8., 3., 4., 7., 5.]\n",
    "plot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15953562-e099-426e-9282-f1caff4dcd1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_transitions = None\n",
    "#all_durations = None\n",
    "for data_str in inpath_pattern:\n",
    "    ### I/O ################################################\n",
    "    all_files = [os.path.join(root, name) for root, dirs, files in os.walk(inpath) for name in files if 'predicted' in os.path.basename(root) and data_str in os.path.basename(root)]\n",
    "    loc_all = {os.path.basename(f):f for f in all_files if 'predicted.json' in f}\n",
    "    loc_summ = [f for f in all_files if 'summary.csv' in f]\n",
    "    loc_trans =  [f for f in all_files if 'transitions.csv' in f]\n",
    "    loc_onoff = [f for f in all_files if 'onoff.json' in f]\n",
    "    \n",
    "    #outpath = os.path.commonpath(fpath.values())\n",
    "    \n",
    "    ### Configuration ################################################\n",
    "    config = yaml.safe_load(open(\"config.yml\", \"r\"))\n",
    "    cluster_color = config['cluster_color']\n",
    "    cluster_group = config['cluster_group_man']\n",
    "    cluster_label = config['cluster_names']\n",
    "    clu_group_label = {_:f'{_}, {__}' for _, __ in tuple(zip([c for c in cluster_label.values()],[g for g in cluster_group.values()]))}\n",
    "    skip_already = config['settings']['skip_already']\n",
    "\n",
    "    ### Load data ################################################\n",
    "    #data_batch = load_tolist(fpath, droplabelcol=False)\n",
    "    #data_batch_concat = pd.concat([d for d in data_batch], axis=0)\n",
    "    \n",
    "    #y_batch_concat = data_batch_concat['prediction']\n",
    "    #y_batch = [d['prediction'] for d in data_batch]\n",
    "\n",
    "    \n",
    "    ### Batch summary ############################################\n",
    "    for i,d in enumerate(loc_summ):\n",
    "        summ_ = pd.read_csv(d)\n",
    "        dev_ = (~summ_.isna()).astype(int)\n",
    "        summ_ = summ_.fillna(0)\n",
    "        #trans_col_ = [[c for c in fr_transition_],[c for c in fr_transition_]]\n",
    "        \n",
    "        if i == 0:\n",
    "            summ = summ_\n",
    "            devider = dev_\n",
    "        else:\n",
    "            summ += summ_\n",
    "            devider += dev_\n",
    "    summary = summ/devider\n",
    "    #summary.to_csv(os.path.join(outpath, f'{data_str}_batch_summary.csv'))\n",
    "    \n",
    "    total_dur = summary.duration_mean*summary.duration_count\n",
    "    total_dur_rel = total_dur/total_dur.sum()\n",
    "    \n",
    "    ### Batch transitions ############################################\n",
    "    #batch_transitions = np.full((len(loc_trans),9,9), np.nan) # with shape recordings,cluster from, cluster to        \n",
    "    for i,d in enumerate(loc_trans):\n",
    "        fr_transition_ = pd.read_csv(d, index_col=0)\n",
    "        #batch_transitions[i] = fr_transition_\n",
    "        trans_col_ = [[c for c in fr_transition_],[c for c in fr_transition_]]\n",
    "        if i == 0:\n",
    "            fr_transition = fr_transition_\n",
    "            trans_col = trans_col_\n",
    "        elif trans_col_ == trans_col:\n",
    "            #print('this')\n",
    "            fr_transition += fr_transition_\n",
    "        else:\n",
    "            print('WARNING')\n",
    "\n",
    "    # merge all transitions across animals and experiments\n",
    "    #if all_transitions is None:\n",
    "    #    all_transitions = np.array([batch_transitions])\n",
    "    #else:\n",
    "    #    all_transitions,batch_transitions = padtoequalsize(all_transitions, batch_transitions, [-3])\n",
    "    #     all_transitions = np.concatenate([all_transitions,[batch_transitions]],axis=0)\n",
    "\n",
    "    # calculate the normalised transition and cluster\n",
    "    # cluster behaviors with single linkage\n",
    "    Z = linkage(fr_transition, 'single', optimal_ordering=True)\n",
    "    # extract closest cluster\n",
    "    ordering = np.concatenate((Z[::-1,0],Z[:,1]))\n",
    "    ordering = ordering[ordering<len(cluster_label)]-1\n",
    "    # calculate normalised transitions\n",
    "    fr_trans_norm = (fr_transition/fr_transition.sum(axis=0)).fillna(0).iloc[1:,1:]\n",
    "    fr_transition_clust = fr_trans_norm.iloc[ordering,ordering]\n",
    "    #fr_trans_norm.to_csv(os.path.join(outpath, f'{data_str}_batch_transitions_2.csv'), index=False)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ### Batch durations ############################################\n",
    "    #batch_durations = None\n",
    "    for rec in loc_onoff:\n",
    "        with open(rec,'r') as jf:\n",
    "            onoff = json.load(jf)\n",
    "        duration = pd.DataFrame(dtype='float64')\n",
    "        for cluster in onoff: #for bout in cluster\n",
    "            cluster_dur = []\n",
    "            for bout in onoff[cluster]: #for bout in cluster\n",
    "                cluster_dur.append(bout[1])\n",
    "            duration = pd.concat([duration,pd.DataFrame([cluster_dur],index=[eval(cluster)],dtype='float64')],axis=0)\n",
    "            \n",
    "        cl_present = duration.index\n",
    "        cl_range = range(min(cl_present), max(cl_present)+1)\n",
    "        duration = duration.reindex(cl_range)\n",
    "        \n",
    "        #if batch_durations is None:\n",
    "        #    batch_durations = np.array([duration.values])\n",
    "        #else:\n",
    "        #    batch_durations, duration = padtoequalsize(batch_durations, duration, [-1,-2])\n",
    "        #    batch_durations = np.concatenate([batch_durations,[duration]],axis=0)\n",
    "    \n",
    "    #if all_durations is None:\n",
    "    #    all_durations = np.array([batch_durations])\n",
    "    #else:\n",
    "    #    all_durations,batch_durations = padtoequalsize(all_durations, batch_durations, [-1,-2,-3])\n",
    "    #    all_durations = np.concatenate([all_durations,[batch_durations]],axis=0)\n",
    "    \n",
    "        \n",
    "    #############\n",
    "    ### plots ###\n",
    "    #############\n",
    "    \n",
    "    if plot:\n",
    "        \"\"\"\n",
    "        transition_plot = vis.transition_plotter(fr_trans_norm.values, cluster_color, node_alpha=summary['duration_relative'].fillna(0).tolist())\n",
    "        plt.text(1.5, -1, f'{data_str}\\nN = {len(loc_trans)}', fontsize=12)\n",
    "        plt.title(f\"transitions of {data_str}\")\n",
    "        plt.savefig(os.path.join(outpath, f'{data_str}_batch_transitions.pdf'))\n",
    "        plt.show()\"\"\"\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        axs1 = fig.add_axes([0, .895, .2, .805])\n",
    "        axs1.axis('off')\n",
    "        dn = dendrogram(Z, orientation='left',ax= axs1)\n",
    "        axs2 = fig.add_axes([0.33, .9, .8, .8])\n",
    "        im = axs2.imshow(fr_transition_clust,norm=colors.PowerNorm(.4,vmax=1))#vmin=0,vmax=.2)#\n",
    "        axs2.set_xticks(range(len(cluster_group)))\n",
    "        axs2.set_xticklabels([cluster_group[k] for k in ordering], rotation=45,ha=\"center\")\n",
    "        axs2.set_yticks(range(len(cluster_group)))\n",
    "        axs2.set_yticklabels([cluster_group[k] for k in ordering])\n",
    "        cbar = axs2.figure.colorbar(im, ax=axs2)\n",
    "        cbar.ax.set_ylabel(\"X^0.4 normalization\", rotation=90, labelpad= 6)\n",
    "        axs2.set_title(f\"transitions of {data_str} per sec (x to y)\")\n",
    "        #plt.savefig(os.path.join(outpath, f'{data_str}_batch_transitheatmap_clust.pdf'),bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "    \n",
    "        if WT_ordering:\n",
    "            fr_transition_WT = fr_trans_norm.iloc[WT_ordering,WT_ordering]\n",
    "            fig = plt.figure()\n",
    "            axs1 = fig.add_axes([0, .895, .2, .805])\n",
    "            axs1.axis('off')\n",
    "            #dn = dendrogram(Z, orientation='left',ax= axs1)\n",
    "            axs2 = fig.add_axes([0.33, .9, .8, .8])\n",
    "            im = axs2.imshow(fr_transition_WT,norm=colors.PowerNorm(.4,vmax=1))#vmin=0,vmax=.2)#\n",
    "            axs2.set_xticks(range(len(cluster_group)-1))\n",
    "            axs2.set_xticklabels([cluster_group[k] for k in WT_ordering], rotation=45,ha=\"center\")\n",
    "            axs2.set_yticks(range(len(cluster_group)-1))\n",
    "            axs2.set_yticklabels([cluster_group[k] for k in WT_ordering])\n",
    "            cbar = axs2.figure.colorbar(im, ax=axs2)\n",
    "            cbar.ax.set_ylabel(\"X^0.4 normalization\", rotation=90, labelpad= 6)\n",
    "            axs2.set_title(f\"transitions of {data_str} per sec (x to y)\")\n",
    "            #plt.savefig(os.path.join(outpath, f'{data_str}_batch_transitheatmap_WTclust.pdf'),bbox_inches = \"tight\")\n",
    "            plt.show()\n",
    "        \n",
    "    \n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(2,5))\n",
    "        b = ax.barh(range(len(total_dur_rel)),total_dur_rel, color=list(cluster_color.values())[1:])\n",
    "        ax.set_yticks(range(len(cluster_group)-1))\n",
    "        ax.set_yticklabels([cluster_group[k] for k in cluster_group][1:])\n",
    "        ax.bar_label(b, label_type='edge', fmt='%.2g', padding=3)\n",
    "        ax.invert_yaxis()\n",
    "        plt.xlabel(f\"total rel. duration\")\n",
    "        plt.title(data_str)\n",
    "        plt.xlim(0,.6)\n",
    "        #plt.savefig(os.path.join(outpath, f'{data_str}_batch_totaldur.pdf'),bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "    \n",
    "        # Calculate onoff sets\n",
    "        onoff = proc.onoff_dict(y_batch, labels =np.unique(y_batch_concat))\n",
    "    \n",
    "        fig = plt.figure(figsize=(.6*len(onoff.keys()),3), layout='constrained')\n",
    "        for k in onoff.keys():\n",
    "            if not np.isnan(k):\n",
    "                durs = pd.DataFrame(onoff[k])[1]/30\n",
    "                plt.boxplot(durs, positions=[k], widths=.5,sym='', patch_artist = True, boxprops={'facecolor':cluster_color[k]},medianprops={'color':'k'})\n",
    "        plt.xticks(range(len(cluster_group)-1),[cluster_group[k] for k in cluster_group][1:], rotation=45)\n",
    "        plt.ylabel(\"sec\")\n",
    "        plt.ylim(0,30)\n",
    "        plt.title(f\"duration of {data_str} (without fliers)\")\n",
    "        #plt.savefig(os.path.join(outpath, f'{data_str}_batch_durboxplot.pdf'),bbox_inches = \"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca73a0d-443b-4b74-9143-f313252531da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fr_transition_WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3e1537-aaa3-48b6-9e56-7fb7042dd581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6958e3-3b1c-4df6-8df0-a1fd990ddd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1cabf-c47a-401a-b8a3-285c40b42e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_withnans_alignright(df_):\n",
    "    df = df_.copy()\n",
    "    for i in range(len(df.columns)):\n",
    "        nulls = df.iloc[np.where(df.iloc[:,i].notnull())[0][-1]+1:,i]\n",
    "        notnulls = df.iloc[:np.where(df.iloc[:,i].notnull())[0][-1],i]\n",
    "        right_aligned = pd.concat([nulls,notnulls], axis=0).reset_index(drop=True)\n",
    "        df.iloc[:,i] = right_aligned\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e006eda-6be7-4aa9-81fa-5518d789c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(96)\n",
    "bout_all = pd.DataFrame([])\n",
    "bout_pre_all = pd.DataFrame([])\n",
    "y_pre_all = pd.DataFrame([])\n",
    "bout_post_all = pd.DataFrame([])\n",
    "y_post_all = pd.DataFrame([])\n",
    "feat = 'velocity'\n",
    "cl = 1\n",
    "rdm_subset = np.random.choice(len(onoff[cl]), 100, replace=False)\n",
    "rdm_ons =[]\n",
    "for i,oo in enumerate(rdm_subset):\n",
    "    rdm_ons.append(onoff[cl][oo][0])\n",
    "    onset = onoff[cl][oo][0]\n",
    "    offset = onoff[cl][oo][0]+onoff[cl][oo][1]\n",
    "    bout = data_batch_concat.reset_index(drop=True)[onset:offset].reset_index(drop=True)\n",
    "    if all(bout[feat].isnull()):\n",
    "        print(i)\n",
    "        continue\n",
    "    bout_pre = data_batch_concat.reset_index(drop=True)[onset-60:onset].reset_index(drop=True)\n",
    "    bout_post = data_batch_concat.reset_index(drop=True)[offset:offset+60].reset_index(drop=True)\n",
    "    \n",
    "    bout_all = pd.concat([bout_all,bout[feat]], axis=1)\n",
    "\n",
    "    bout_pre_all = pd.concat([bout_pre_all,bout_pre[feat]], axis=1)\n",
    "    y_pre_all = pd.concat([y_pre_all,bout_pre['prediction']], axis=1)\n",
    "    bout_post_all = pd.concat([bout_post_all,bout_post[feat]], axis=1)\n",
    "    y_post_all = pd.concat([y_post_all,bout_post['prediction']], axis=1)\n",
    "\n",
    "bout_all.columns = list(range(len(bout_all.columns)))\n",
    "bout_pre_all.columns = list(range(len(bout_pre_all.columns)))\n",
    "y_pre_all.columns = list(range(len(y_pre_all.columns)))\n",
    "y_pre_color = y_pre_all[:150].replace(cluster_color)\n",
    "bout_post_all.columns = list(range(len(bout_post_all.columns)))\n",
    "y_post_all.columns = list(range(len(y_post_all.columns)))\n",
    "y_post_color = y_post_all[:150].replace(cluster_color)\n",
    "\n",
    "bout_all_right = df_withnans_alignright(bout_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e4158-0d21-4595-ac85-ec09628a9921",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "mask = data_batch_concat.prediction.isin([7])\n",
    "#fig = px.lines(bout_all, color = y_bout_all, width=800, height=400)\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "for trace in bout_all:\n",
    "    bout_ = bout_all[trace].iloc[:90].dropna().reset_index(drop=True)\n",
    "    bout_r_ = bout_all_right[trace].iloc[-90:].dropna().reset_index(drop=True)\n",
    "    pre_ = bout_pre_all[trace][y_pre_all[trace]==y_pre_all[trace].iloc[-1]].reset_index(drop=True)\n",
    "    post_ = bout_post_all[trace][y_post_all[trace]==y_post_all[trace].iloc[-1]].reset_index(drop=True)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(bout_)), y=bout_, line=dict(color=cluster_color[cl]),mode='lines'),\n",
    "                 row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(-len(pre_),0), y=pre_, line=dict(color=y_pre_color[trace].iloc[-1]),mode='lines'),\n",
    "                 row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(-len(bout_r_),0), y=bout_r_, line=dict(color=cluster_color[cl]),mode='lines'),\n",
    "                 row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(post_)), y=post_, line=dict(color=y_post_color[trace].iloc[-1]),mode='lines'),\n",
    "                 row=1, col=2)\n",
    "\n",
    "    \n",
    "mean_ = pd.concat([bout_pre_all,bout_all],axis=0).reset_index(drop=True).mean(axis=1).iloc[:150]\n",
    "mean_r_ = pd.concat([bout_all_right, bout_post_all],axis=0).reset_index(drop=True).mean(axis=1).iloc[-150:]\n",
    "fig.add_trace(go.Scatter(x=np.arange(-60,90), y=mean_, line=dict(color='black',width=3),mode='lines'),\n",
    "                 row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=np.arange(-90,60), y=mean_r_, line=dict(color='black',width=3),mode='lines'),\n",
    "                 row=1, col=2)\n",
    "\n",
    "fig.add_vline(x=0, line=dict(color=\"Grey\",width=5))\n",
    "fig.update_xaxes(dtick=15, title=dict(text='Time [frames]'))\n",
    "fig.update_yaxes(range=[0, max(bout_all.max().max(),bout_pre_all.max().max(),bout_post_all.max().max())],title=dict(text=f'{feat}'))\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=500,\n",
    "    xaxis = dict(\n",
    "        tickmode = 'linear',\n",
    "        dtick = 15),\n",
    "    showlegend=False,\n",
    "    template='plotly_white',\n",
    "    title=dict(text=f\"Traces of {cluster_group[cl]} aligned at prediction onset (l) and offset (r)\", font=dict(size=16), x =.5, xanchor='center'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dbbba1-5f2c-4745-9917-f327189b7283",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([bout_pre_all,bout_all], axis=0).reset_index(drop=True)[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ddd09a-4b9b-4827-91ab-9e80261e0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onoff_ = pd.json_normalize(onoff).to_dict(orient='split')\n",
    "onoff_rev = {}\n",
    "for l,c in zip(onoff_['data'][0],onoff_['columns']):\n",
    "    for oo in l:\n",
    "        onoff_rev[oo[0]] = (c, oo[1])\n",
    "\n",
    "onoff_rev_df = pd.DataFrame(onoff_rev).T\n",
    "onoff_rev_df = onoff_rev_df.reindex(sorted(onoff_rev_df.index), axis=0)\n",
    "\n",
    "onoff_rev_dfidx = onoff_rev_df.index.to_series().reset_index(drop=True)\n",
    "prebout_idx = (onoff_rev_dfidx[onoff_rev_dfidx.isin(rdm_ons)].index - 1).tolist()\n",
    "\n",
    "prebout_c, prebout_dur, prebout = onoff_rev_df.iloc[prebout_idx,0],onoff_rev_df.iloc[prebout_idx,1], onoff_rev_df.index[prebout_idx].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f242b-35e0-4594-af30-ddcf25a7e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(8,5), sharey=True)\n",
    "axs[0].plot(range(0,90),bout_all[:90], c=cluster_color[cl],alpha=.7)\n",
    "for b,d,c in zip(prebout,prebout_dur,prebout_c):\n",
    "    axs[0].plot(range(-d if d < 60 else -60,0),data_batch_concat.reset_index(drop=True).iloc[b:b+d][feat][-d if d < 60 else -60:], c=cluster_color[c],alpha=.7)\n",
    "axs[0].plot(range(0,90),bout_all[:90].median(axis=1), c='#252422', linewidth=2)\n",
    "axs[0].axvline(0)\n",
    "axs[0].set_title(\"aligned beginning\")\n",
    "axs[1].plot(range(-90,0),bout_all_right[-90:], c=cluster_color[cl],alpha=.7)\n",
    "axs[1].plot(range(-90,0),bout_all_right[-90:].median(axis=1), c='#252422', linewidth=2)\n",
    "axs[1].axvline(0)\n",
    "axs[1].set_title(\"aligned end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfee0dc-6dfe-41d5-aaf2-dae30852b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_all[trace][y_pre_all[trace]==y_pre_all[trace].iloc[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97d24e-6c8e-4b5f-814a-7e5479d9dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "Z = linkage(fr_transition, 'single', optimal_ordering=True)\n",
    "ordering = np.concatenate((Z[::-1,0],Z[:,1]))\n",
    "ordering = ordering[ordering<=8]\n",
    "fr_trans_norm = (fr_transition/fr_transition.sum(axis=0)).fillna(0)\n",
    "fr_transition_clust = fr_transition.iloc[ordering,ordering]\n",
    "fr_trans_clust_norm = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea81f16-6c0b-42b1-b444-06f98925dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axs1 = fig.add_axes([0, .895, .2, .805])\n",
    "axs1.axis('off')\n",
    "dn = dendrogram(Z, orientation='left',ax= axs1)\n",
    "axs2 = fig.add_axes([0.33, .9, .8, .8])\n",
    "im = axs2.imshow(fr_transition_clust,norm=colors.PowerNorm(.4,vmax=1))#vmin=0,vmax=.2)#\n",
    "axs2.set_xticks(range(len(cluster_group)-1))\n",
    "axs2.set_xticklabels([cluster_group[k] for k in ordering], rotation=45,ha=\"center\")\n",
    "axs2.set_yticks(range(len(cluster_group)-1))\n",
    "axs2.set_yticklabels([cluster_group[k] for k in ordering])\n",
    "cbar = axs2.figure.colorbar(im, ax=axs2)\n",
    "cbar.ax.set_ylabel(\"X^0.4 normalization\", rotation=90, labelpad= 6)\n",
    "axs2.set_title(f\"transitions of {data_str} per sec (x to y)\")\n",
    "plt.savefig(os.path.join(out_predicted, os.path.basename(outpath)+'_batch_transitheatmap_clust.pdf'),bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1805f81-4486-477f-bd8c-2ed01661e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_trans_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0aeb5e-7094-4b85-9e08-bb9d92af84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2/.6*1,5))\n",
    "b = ax.barh(range(len(total_dur_rel)),total_dur_rel, color=list(cluster_color.values())[1:])\n",
    "ax.set_yticks(range(len(cluster_group)-1))\n",
    "ax.set_yticklabels([cluster_group[k] for k in cluster_group][1:])\n",
    "ax.bar_label(b, label_type='edge', fmt='%.2g', padding=3)\n",
    "ax.invert_yaxis()\n",
    "plt.xlabel(f\"total rel. duration\")\n",
    "plt.title(data_str)\n",
    "plt.xlim(0,1)\n",
    "plt.savefig(os.path.join(out_predicted, os.path.basename(outpath)+'_batch_totaldur.pdf'),bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a89a61-fad6-40ec-b19e-995d7aedf8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    data_describe = data_batch_concat.groupby(y_batch_concat).describe().T.loc[idx[:, ['mean','std','count']], :].sort_index(level=0).T\n",
    "    dur_describe = pd.DataFrame(dur, columns=['duration']).groupby(transi).describe().T.loc[idx[:, ['mean','std','count']], :].sort_index(level=0).T\n",
    "    dur_describe['duration','relative'] = pd.DataFrame(dur, columns=['duration']).groupby(transi).apply(lambda cd: cd.sum()/len(y_batch_concat))\n",
    "    summary = pd.concat([dur_describe, data_describe], axis=1)\n",
    "    summary.index.name = 'cluster'\n",
    "    summary = summary.T.reset_index(drop=True).set_index(summary.T.index.map('_'.join)).T\n",
    "    summary = summary.set_index(summary.index.astype(int))\n",
    "    summary = summary.reindex([k for k in cluster_label if k != -1])\n",
    "    summary.to_csv(os.path.join(out_predicted, os.path.basename(outpath)+'_batch_summary.csv'))\n",
    "\n",
    "    #### Older Version\n",
    "    \n",
    "    for i,d in enumerate(data_batch):\n",
    "        frame = d['prediction'].rolling(30).apply(lambda s: s.mode()[0])[29::30].values.flatten()\n",
    "        trans_col_,fr_transition_ = crosstab(frame[1:], frame[:-1], levels=([k for k in cluster_label if k != -1],[k for k in cluster_label if k != -1]))\n",
    "        #fr_transition_ = pd.read_csv() ##################################read transitions.csv should look like normal fr_transition, get trans_col from header\n",
    "        if i == 0:\n",
    "            fr_transition = fr_transition_\n",
    "            trans_col = trans_col_\n",
    "        if trans_col_ == trans_col:\n",
    "            fr_transition += fr_transition_\n",
    "        else:\n",
    "            print('WARNING')\n",
    "        #fr_transition/fr_transition.sum(axis=0)\n",
    "    \n",
    "    #othersum_axis0 = fr_transition.sum(axis=0)-fr_transition.diagonal()\n",
    "    #transition_toother = fr_transition/othersum_axis0\n",
    "    #transition_self = fr_transition.diagonal()/(othersum_axis0+fr_transition.diagonal())\n",
    "    #np.fill_diagonal(transition_toother, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env2",
   "language": "python",
   "name": "sklearn-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b5538c-c780-4848-9d27-e2079b7f5f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import networkx as nx\n",
    "import yaml\n",
    "import json\n",
    "from scipy.stats.contingency import crosstab\n",
    "import scipy\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import pickle\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append((os.path.expanduser('~')))\n",
    "#import functions.visualise as vis\n",
    "import PpaPy.plot2 as vis\n",
    "import functions.process as proc\n",
    "from functions.io import setup_logger, makedir\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58639dd-1006-434c-b377-9f58158a83fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_keys(json_file, key):\n",
    "    def traverse_dict(d, key):\n",
    "        if isinstance(d, dict):\n",
    "            if key in d.keys():\n",
    "                return {key: d[key]}\n",
    "            else:\n",
    "                return {k: traverse_dict(v, key) for k, v in d.items()}\n",
    "        elif isinstance(d, list):\n",
    "            return [traverse_dict(x, key) for x in d]\n",
    "        else:\n",
    "            return d\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    nested_dict = traverse_dict(data, key)\n",
    "    return {(innerKey, outerKey): values for outerKey, innerDict in nested_dict.items() for innerKey, values in innerDict.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129af22c-f15f-425e-98ae-ea9b558f403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_stars(p):\n",
    "    if p <= .01:\n",
    "        return int(-np.ceil(np.log10(abs(p)))) # should be correct needs checking\n",
    "    elif p <= .05:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18efb6f1-ab9d-4f9b-a4ec-50a1e27fd49c",
   "metadata": {},
   "source": [
    "Please provide where your files are stored and where you would like your data to be saved in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a3bd5-29bf-44e3-bbe5-231912f5022c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datestr = time.strftime(\"%Y%m%d-%Hh%Mm\")\n",
    "inpath = \"/gpfs/soma_fs/home/boeger/PpaPred/ErenBoeger_2024\" \n",
    "#inpath = '/gpfs/soma_fs/home/boeger/PpaPred/PpaPred_roca_35727184'\n",
    "\n",
    "outpath = inpath #\"/gpfs/soma_fs/home/boeger/PpaPred/data_eren_26825048\"\n",
    "\n",
    "config_path = \"config.yml\"\n",
    "\n",
    "# Eren Boeger 2024\n",
    "include, fig = [\"Exp1_WT_larvae\", \"Exp1_WT_OP50\"], \"Exp1\"   \n",
    "#include, fig = [\"Exp2_WT_larvae\", \"Exp2_tdc1_larvae\", \"Exp2_tbh1_larvae\"], \"Exp2\"\n",
    "#include, fig = [\"Exp3_ser3_larvae\", \"Exp3_ser6_larvae\", \"Exp3_lgc55_larvae\"], \"Exp3\"\n",
    "#include, fig = [\"Supp5_WT_larvae\", \"Supp5_tyramine_larvae\", \"Supp5_octopamine_larvae\"], \"Supp5\"\n",
    "#include, fig = [\"Exp2_tph1_larvae\", \"Exp2_cat2_larvae\", \"Supp4_tbh1tdc1_larvae\"], \"Supp4\"\n",
    "#include, fig = [ \"Exp3_octr1_larvae\", \"Exp3_tyra2_larvae\", \"Exp3_ser2_larvae\", \"Exp3_tyra3_larvae\", \"Supp7_ser2tyra2tyra3_larvae\"], \"Supp7\"\n",
    "\n",
    "#include, fig = ['Exp2_WT_larvae_0624','Exp2_tph1_larvae', 'Exp2_cat2_larvae', ,\"Exp2_tbh1tdc1_larvae\"], 'Supp4_Pharma' #transitions\n",
    "#include, fig = ['Exp3_WT_larvae',\"Exp3_tyra2_larvae\", \"Exp3_ser2_larvae\", \"Exp3_tyra3_larvae\",\"Exp3_tyra2tyra3ser2_larvae\"], 'Supp7_Pharma' # transitions\n",
    "\n",
    "file_pattern = 'batch.json'\n",
    "inpath_with_subfolders = True\n",
    "\n",
    "Z_path = False #os.path.join(inpath,f'Exp1_WT_larvae_linkage_other_norm_out.pkl')\n",
    "plot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb2869-bbe9-49fa-bee4-a11a39a8e5f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_transitions = None\n",
    "#all_durations = None\n",
    "\n",
    "### I/O ################################################\n",
    "all_files = [os.path.join(root, name) for root, dirs, files in os.walk(inpath) for name in files if file_pattern in name and any([c in name for c in include]) and name.endswith('json')]\n",
    "all_files.sort(key = lambda i: np.where([c in i for c in include])) # to sort all_files as given in include\n",
    "loc_all = {os.path.basename(f):f for f in all_files}\n",
    "\n",
    "outpath = makedir(os.path.join(inpath,fig))\n",
    "    \n",
    "### Configuration ################################################\n",
    "config = yaml.safe_load(open(config_path, \"r\"))\n",
    "cluster_color = config['cluster_color']\n",
    "cluster_group = config['cluster_labels']\n",
    "cluster_label = config['cluster_labels']\n",
    "clu_group_label = {_:f'{_}, {__}' for _, __ in tuple(zip([c for c in cluster_label.values()],[g for g in cluster_group.values()]))}\n",
    "skip_already = config['settings']['skip_already']\n",
    "fps = 30\n",
    "loc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83baf927-4759-4a68-9956-d32a565532cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "def transplot(fr_transition_norm, ordering=None, cmap='viridis', vmin=0, vmax=1, linked=None, label='[]'):\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    if ordering is None:\n",
    "        ordering = list(range(len(fr_transition_norm)))\n",
    "    \n",
    "    if linked is not None:\n",
    "        axs1 = fig.add_axes([0, .895, .2, .805])\n",
    "        axs1.axis('off')\n",
    "        dn = dendrogram(linked, orientation='left',ax= axs1, color_threshold=0,above_threshold_color='k')\n",
    "        \n",
    "    axs2 = fig.add_axes([0.35, .9, .8, .8])    \n",
    "    im = axs2.imshow(fr_transition_norm.iloc[ordering,ordering], cmap =cmap, vmin=vmin, vmax=vmax) # x state i y state i+1\n",
    "    axs2.set_xticks(range(len(ordering)))\n",
    "    axs2.set_xticklabels([cluster_group[k] for k in ordering], rotation=45,ha=\"center\")\n",
    "    axs2.set_xlabel('State i')\n",
    "    axs2.set_yticks(range(len(ordering)))\n",
    "    axs2.set_yticklabels([cluster_group[k] for k in ordering])\n",
    "    axs2.set_ylabel('State i+1')\n",
    "    cbar = axs2.figure.colorbar(im, ax=axs2)\n",
    "    #cbar.ax.set_ylabel(\"X^0.4 normalization\", rotation=90, labelpad= 6)\n",
    "    axs2.set_title(f\"{label}\")\n",
    "    #axs2.set_title(f\"transitions per sec\\n{label}\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a3531-8dda-4180-ba16-58b10b47318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a355e849-5250-4da5-b2c5-9ecdeb71d905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric = 'mean transitions'\n",
    "outmetric = os.path.join(outpath, f\"{datestr}_{''.join(metric.split(' '))}_Utest\")\n",
    "\n",
    "metric_multi = None\n",
    "for fn, fpath in loc_all.items():\n",
    "    batch_metric = pd.DataFrame(load_data_from_keys(fpath, metric)).droplevel(0, axis=1)\n",
    "    batch_metric.columns = pd.MultiIndex.from_product([[fn], batch_metric.columns])\n",
    "    if metric_multi is None:\n",
    "        metric_multi = batch_metric\n",
    "    else:\n",
    "        metric_multi = pd.concat([metric_multi, batch_metric], axis=1)\n",
    "    #batch_etho = load_data_from_keys(fpath, 'ethogram')\n",
    "if metric == 'mean duration':\n",
    "    metric_multi = metric_multi/fps\n",
    "metric_multi.index.name = 'cluster'\n",
    "\n",
    "all_conds = metric_multi.columns.get_level_values(0).unique()\n",
    "id_cond = [c.split('_')[0] for c in all_conds]\n",
    "metric_multi.index = pd.MultiIndex.from_tuples([eval(i) for i in metric_multi.index])\n",
    "metric_multi = metric_multi.drop(-1, level = 0)\n",
    "metric_multi = metric_multi.drop(-1, level = 1)\n",
    "\n",
    "\n",
    "all_trans = {}\n",
    "trans_suffix = '_other_norm_out'\n",
    "for i, cond in enumerate(all_conds):\n",
    "    fr_transition = metric_multi[cond].mean(axis=1).unstack(level=0).fillna(0)\n",
    "    fr_transition_norm = (fr_transition/fr_transition.sum(axis=0))\n",
    "\n",
    "    trans_self = np.diagonal(fr_transition.values)\n",
    "    trans_other = fr_transition.copy()\n",
    "    np.fill_diagonal(trans_other.values, 0)\n",
    "\n",
    "    all_trans[cond] = fr_transition\n",
    "    all_trans[cond+'_norm_out'] = (fr_transition/fr_transition.sum(axis=0))\n",
    "    all_trans[cond+'_norm_in'] = (fr_transition.T/fr_transition.sum(axis=1)).T\n",
    "    all_trans[cond+'_self'] = trans_self\n",
    "    all_trans[cond+'_other'] = trans_other\n",
    "    all_trans[cond+'_self_norm'] =  trans_self/trans_self.sum()\n",
    "    all_trans[cond+'_other_norm_out'] = trans_other/trans_other.sum(axis=0)\n",
    "    all_trans[cond+'_other_norm_in'] = (trans_other.T/trans_other.sum(axis=1)).T\n",
    "    all_trans[cond+'_other_norm_inout'] = pd.DataFrame(np.triu(trans_other)/np.sum(np.triu(trans_other))+np.tril(trans_other)/np.sum(np.tril(trans_other)))\n",
    "    \n",
    "    #\n",
    "    #np.round(all_trans[cond+trans_suffix],4).to_csv(os.path.join(inpath, fig, f'{cond.replace(\"_batch.json\",\"\")}_transitions{trans_suffix}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51389478-0afa-4cec-a418-3392b6dbb577",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de55f2c-3fcd-4dde-a7e2-d5a6a70f8c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if Z_path == False:\n",
    "    # trans_suffix is other_normed_out\n",
    "    baseline_trans = all_trans[include[0]+'_batch.json'+trans_suffix].copy()\n",
    "    \n",
    "    method_str = 'DistSymNormSum'\n",
    "    baseline_dist = (1/((baseline_trans+np.triu(baseline_trans).T+np.tril(baseline_trans).T)))\n",
    "    np.fill_diagonal(baseline_dist.values,0)\n",
    "    baseline_dist_norm = baseline_dist/sum(baseline_dist)\n",
    "    \n",
    "    baseline_dist_sq = scipy.spatial.distance.squareform(baseline_dist_norm)\n",
    "    Z = linkage(baseline_dist_sq, 'single', optimal_ordering=True)#ward #complete\n",
    "    \n",
    "    # PLots\n",
    "    ordering = dendrogram(Z)['leaves'][::-1]\n",
    "    plt.show()\n",
    "    \n",
    "    dist_plot = transplot(baseline_dist_norm, ordering, linked=Z, label='Distance: 1/((transition_out + transitions_in)/sum(transitions)')#linked=Z,     plt.savefig(os.path.join(inpath,fig,f'{include[0]}_{method_str}_distancematrix_oneminus.pdf'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    org_plot = transplot(baseline_trans, ordering, linked=Z, label='original transitions')#linked=Z,\n",
    "    #plt.savefig(os.path.join(inpath,fig,f'{include[0]}_{method_str}_transitionmatrix_oneminus.pdf'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Save\n",
    "    np.round(baseline_dist_norm,4).to_csv(os.path.join(inpath, fig, f'{include[0]}_distance_other_normTotal.csv'))\n",
    "    #with open(os.path.join(inpath, fig, f'{include[0]}_linkage{trans_suffix}.pkl'), 'wb') as f:  # open a text file\n",
    "        #pickle.dump(Z, f) # serialize the list\n",
    "\n",
    "elif isinstance(Z_path,str):\n",
    "    with open(Z_path, 'rb') as f:  # open a text file\n",
    "        Z = pickle.load(f)\n",
    "        ordering = dendrogram(Z)['leaves'][::-1]\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ef355-5dd7-441b-945b-ba6d9caf2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "outmetric = os.path.join(outpath, f\"{datestr}_{''.join('rel time in'.split(' '))}_Utest\")\n",
    "\n",
    "metric_multi_reltime = None\n",
    "for fn, fpath in loc_all.items():\n",
    "    batch_metric = pd.DataFrame(load_data_from_keys(fpath, 'rel time in')).droplevel(0, axis=1)\n",
    "    batch_metric.columns = pd.MultiIndex.from_product([[fn], batch_metric.columns])\n",
    "    if metric_multi_reltime is None:\n",
    "        metric_multi_reltime = batch_metric\n",
    "    else:\n",
    "        metric_multi_reltime = pd.concat([metric_multi_reltime, batch_metric], axis=1)\n",
    "    #batch_etho = load_data_from_keys(fpath, 'ethogram')\n",
    "metric_multi_reltime.index.name = 'cluster'\n",
    "nodes_alpha = metric_multi_reltime.groupby(level=0, axis=1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6c4819-73fe-4ad4-88cc-5a625faa2c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_rel*100, all_trans[cond+trans_suffix]*100, .1*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7641dd-1d5f-4751-815a-0ab614ec4692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, cond in enumerate(all_conds):\n",
    "    transplot_cond = transplot(all_trans[cond+trans_suffix], ordering, linked=Z, label=cond+trans_suffix)# vmax=.3)#linked=Z, \n",
    "    plt.savefig(os.path.join(inpath,fig,f'{cond.split(\".\")[0]}_transitions{trans_suffix}.pdf'),  bbox_inches=\"tight\")\n",
    "\n",
    "    trans_rel = (all_trans[cond+trans_suffix]-all_trans[include[0]+'_batch.json'+trans_suffix])*metric_multi_reltime[cond].mean(axis=1).values\n",
    "    transplot_diff = transplot(trans_rel, ordering,  cmap='RdBu_r',linked=Z, vmin=-.1,vmax=.1, label=cond+trans_suffix+' diff WT larvae')#linked=Z, \n",
    "    plt.savefig(os.path.join(inpath,fig,f'{cond.split(\".\")[0]}_transitions_relto_WTlarvae{trans_suffix}.pdf'),  bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a78ca2-0695-490d-b4f1-d82aeebeac1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, cond in enumerate(all_conds):\n",
    "    \n",
    "    mean_metric = metric_multi_reltime[cond].mean(axis=1)\n",
    "    trans_ = all_trans[cond+trans_suffix]\n",
    "    trans_self = all_trans[cond+'_self_norm']\n",
    "    \n",
    "    trans_other_alpha = trans_.T.values.flatten()\n",
    "    trans_other_alpha = trans_other_alpha[trans_other_alpha>0]\n",
    "    trans_other_alpha[trans_other_alpha >= .2] = 1\n",
    "    trans_other_alpha[trans_other_alpha < .25] = .25\n",
    "    \n",
    "    label = (((mean_metric*100).round().astype(int)).astype(str)+ '%').to_dict()\n",
    "    transition_plot = vis.transition_plotter(trans_.values.copy(), cluster_color,#trans_self.copy(), \n",
    "                                             node_alpha=nodes_alpha[cond], edge_alpha=trans_other_alpha.T, clu_group_label=label)\n",
    "    plt.text(1.5, -1, f'{cond}\\nN = {len(metric_multi_reltime[cond].T)}', fontsize=12)\n",
    "    plt.title(f\"transitions of {cond}\")\n",
    "    #\"plt.savefig(os.path.join(inpath,fig,f'{cond.split(\".\")[0]}_transdiagramm{trans_suffix}.pdf'),  bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab6db5e3-290b-41ce-8ad7-abd2778f0dc2",
   "metadata": {},
   "source": [
    "# Detect communities using SBM\n",
    "communities = nx.community.louvain_communities(G,resolution=1.3)\n",
    "communities\n",
    "\n",
    "#for c in communities:\n",
    "mod = nx.community.modularity(G,communities)\n",
    "# Print the detected communities\n",
    "#for i, community in enumerate(communities):\n",
    "#    print(f\"Community {i + 1}: {community}\")\n",
    "print(communities, mod, nx.community.partition_quality(G,communities))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a642ac95-563b-425e-9a8c-218147440da8",
   "metadata": {},
   "source": [
    "mc.draw_graph(G, communities, node_size=300, with_labels=True, edge_color=\"silver\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fcd6710-da3c-4bac-a1b9-8c5105c64260",
   "metadata": {},
   "source": [
    "from cdlib import evaluation\n",
    "mod = evaluation.newman_girvan_modularity(G,communities)\n",
    "communities.communities, mod"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8c851f8-aa00-42eb-b332-418a2bd1a980",
   "metadata": {},
   "source": [
    "g = nx.karate_club_graph()\n",
    "communities = surprise_communities(g)\n",
    "mod = modularity(g,communities.communities)\n",
    "communities.communities, mod"
   ]
  },
  {
   "cell_type": "raw",
   "id": "008bc681-b65f-4280-a28d-3ac88526c327",
   "metadata": {},
   "source": [
    "edges = []\n",
    "weights = []\n",
    "for i in range(baseline_trans.shape[0]):\n",
    "    for j in range(baseline_trans.shape[1]):\n",
    "        if baseline_trans.values[i,j] > 0:\n",
    "            edges.append((i,j))\n",
    "            weights.append(np.round(baseline_trans.values[i,j],4))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cbf82e5-85b5-493c-a695-465514d4dc23",
   "metadata": {},
   "source": [
    "import igraph as ig\n",
    "g = ig.Graph(directed=True)\n",
    "g.add_vertices(6)\n",
    "g.add_edges(edges)\n",
    "g.es['weight'] = weights\n",
    "vertex_weight = list(metric_multi_reltime.groupby(level=0, axis=1).mean()[include[0]+'_batch.json'])\n",
    "\n",
    "# Run Walktrap\n",
    "clusters = g.community_edge_betweenness(clusters=3,weights='weight')\n",
    "clusters.as_clustering().membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67cc4b5-fccc-4340-890b-935fdde825fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "9e08215a-474e-49da-8dfd-3f56d920b3d3",
   "metadata": {},
   "source": [
    "n = g.to_networkx()\n",
    "pos = nx.spring_layout(n)\n",
    "edge_labels = nx.get_edge_attributes(n, 'weight')\n",
    "nx.draw_networkx_edge_labels(n,pos, edge_labels=edge_labels, label_pos=.8)\n",
    "nx.draw(n, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f013f-4797-4ba0-b915-957004cd2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trans[cond+'_other'], pd.DataFrame(np.triu(all_trans[cond+'_other'])/np.sum(np.triu(all_trans[cond+'_other']))+np.tril(all_trans[cond+'_other'])/np.sum(np.tril(all_trans[cond+'_other']))), np.sum(np.triu(all_trans[cond+'_other']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb73641-613d-4b8e-814e-e9b004f575bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trans[cond+'_other_norm_inout'], np.sum(np.triu(all_trans[cond+'_other_norm_inout'])), np.sum(np.tril(all_trans[cond+'_other_norm_inout']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f3400-e8a1-4d87-9a27-a84426b9bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trans_single = {}\n",
    "for i, cond in enumerate(all_conds):\n",
    "    firstcol = metric_multi[cond].columns[1]\n",
    "    fr_transition = metric_multi[(cond,firstcol)].unstack(level=0).fillna(0)\n",
    "    fr_transition_norm = (fr_transition/fr_transition.sum(axis=0))\n",
    "\n",
    "    trans_self = np.diagonal(fr_transition.values)\n",
    "    trans_other = fr_transition.copy()\n",
    "    np.fill_diagonal(trans_other.values, 0)\n",
    "\n",
    "    all_trans_single[cond] = fr_transition\n",
    "    all_trans_single[cond+'_norm_out'] = (fr_transition/fr_transition.sum(axis=0))\n",
    "    all_trans_single[cond+'_norm_in'] = (fr_transition/fr_transition.sum(axis=1))\n",
    "    all_trans_single[cond+'_self'] = trans_self\n",
    "    all_trans_single[cond+'_other'] = trans_other\n",
    "    all_trans_single[cond+'_self_norm'] =  trans_self/trans_self.sum()\n",
    "    all_trans_single[cond+'_other_norm_out'] = trans_other/trans_other.sum(axis=0)\n",
    "    all_trans_single[cond+'_other_norm_in'] = trans_other/trans_other.sum(axis=1)\n",
    "\n",
    "    transplot_cond_single = transplot(all_trans_single[cond+trans_suffix], ordering, linked=Z, label=firstcol)\n",
    "    #plt.savefig(os.path.join(inpath,fig,f'{cond.split(\".\")[0]}_transitions.pdf'),  bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4f667-46d5-49ec-beff-2479561db1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(trans_.values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29016ed6-1f76-4ef9-8afc-38e4d94ea824",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727b75f-5f4a-4266-abb7-1d2a26b0268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dendrogram(Z)['leaves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80eafd-137c-4126-8ce6-cd78d30ce72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_json = {'meta':{'metric': metric,\n",
    "                          'statistical test': 'Mann-Whitney-U-Test, two-sided',\n",
    "                          'bonferroni correction': 'statsmodels...multipletests',\n",
    "                          'population': stat_pop},\n",
    "              'adjusted ps': all_ps.to_dict(),\n",
    "              'Mann-Whitney U': all_U1s.to_dict(),\n",
    "              'unadjusted ps': all_ps_orig.to_dict(),\n",
    "              }\n",
    "jsnF = json.dumps(stats_json, indent = 4)\n",
    "with open(os.path.join(outpath, f'{datestr}_{metric}_Utest.json'), \"w\") as outfile:\n",
    "    outfile.write(jsnF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5578a9-b25f-4d11-8012-710a71d10bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [eval(i) for i in metric_multi.index]\n",
    "type(li[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55cf402-4375-491a-bec0-160566a660fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "op.itemgetter('metric', 'statistical test', 'bonferroni correction', 'population')(stats_json)\n",
    "op.getitem(stats_json,'metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce2244c-ad50-4d43-8adf-d687dd94de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "U1s, pvs = stats.mannwhitneyu(metric_multi[stat_pop], metric_multi['bac_data_batch.json'], axis=1, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d4a4d4-cb23-4e15-9113-820f7e1051f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "___,ps_adjusted,__,_ = multipletests(pvs, method='bonferroni')\n",
    "np.round(ps_adjusted,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23acf27-94f7-4dfb-bb7d-e569a797ff33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    ### Load data ################################################\n",
    "    #data_batch = load_tolist(fpath, droplabelcol=False)\n",
    "    #data_batch_concat = pd.concat([d for d in data_batch], axis=0)\n",
    "    \n",
    "    #y_batch_concat = data_batch_concat['prediction']\n",
    "    #y_batch = [d['prediction'] for d in data_batch]\n",
    "\n",
    "    \n",
    "    ### Batch summary ############################################\n",
    "    for i,d in enumerate(loc_summ):\n",
    "        summ_ = pd.read_csv(d)\n",
    "        dev_ = (~summ_.isna()).astype(int)\n",
    "        summ_ = summ_.fillna(0)\n",
    "        #trans_col_ = [[c for c in fr_transition_],[c for c in fr_transition_]]\n",
    "        \n",
    "        if i == 0:\n",
    "            summ = summ_\n",
    "            devider = dev_\n",
    "        else:\n",
    "            summ += summ_\n",
    "            devider += dev_\n",
    "    summary = summ/devider\n",
    "    #summary.to_csv(os.path.join(outpath, f'{data_str}_batch_summary.csv'))\n",
    "    \n",
    "    total_dur = summary.duration_mean*summary.duration_count\n",
    "    total_dur_rel = total_dur/total_dur.sum()\n",
    "    \n",
    "    ### Batch transitions ############################################\n",
    "    #batch_transitions = np.full((len(loc_trans),9,9), np.nan) # with shape recordings,cluster from, cluster to        \n",
    "    for i,d in enumerate(loc_trans):\n",
    "        fr_transition_ = pd.read_csv(d, index_col=0)\n",
    "        #batch_transitions[i] = fr_transition_\n",
    "        trans_col_ = [[c for c in fr_transition_],[c for c in fr_transition_]]\n",
    "        if i == 0:\n",
    "            fr_transition = fr_transition_\n",
    "            trans_col = trans_col_\n",
    "        elif trans_col_ == trans_col:\n",
    "            #print('this')\n",
    "            fr_transition += fr_transition_\n",
    "        else:\n",
    "            print('WARNING')\n",
    "\n",
    "    # merge all transitions across animals and experiments\n",
    "    #if all_transitions is None:\n",
    "    #    all_transitions = np.array([batch_transitions])\n",
    "    #else:\n",
    "    #    all_transitions,batch_transitions = padtoequalsize(all_transitions, batch_transitions, [-3])\n",
    "    #     all_transitions = np.concatenate([all_transitions,[batch_transitions]],axis=0)\n",
    "\n",
    "    # calculate the normalised transition and cluster\n",
    "    # cluster behaviors with single linkage\n",
    "    Z = linkage(fr_transition, 'single', optimal_ordering=True)\n",
    "    # extract closest cluster\n",
    "    ordering = np.concatenate((Z[::-1,0],Z[:,1]))\n",
    "    ordering = ordering[ordering<len(cluster_label)]-1\n",
    "    # calculate normalised transitions\n",
    "    fr_trans_norm = (fr_transition/fr_transition.sum(axis=0)).fillna(0)\n",
    "    fr_transition_clust = fr_trans_norm.iloc[ordering,ordering]\n",
    "    fr_trans_norm.to_csv(os.path.join(outpath, f'{data_str}_batch_transitions_2.csv'), index=False)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ### Batch durations ############################################\n",
    "    #batch_durations = None\n",
    "    for rec in loc_onoff:\n",
    "        with open(rec,'r') as jf:\n",
    "            onoff = json.load(jf)\n",
    "        #duration = pd.DataFrame(dtype='float64')\n",
    "        for cluster in onoff: #for bout in cluster\n",
    "            cluster_dur = []\n",
    "            for bout in onoff[cluster]: #for bout in cluster\n",
    "                cluster_dur.append(bout[1])\n",
    "            #duration = pd.concat([duration,pd.DataFrame([cluster_dur],index=[eval(cluster)],dtype='float64')],axis=0)\n",
    "            \n",
    "        cl_present = duration.index\n",
    "        cl_range = range(min(cl_present), max(cl_present)+1)\n",
    "        duration = duration.reindex(cl_range)\n",
    "        \n",
    "        if batch_durations is None:\n",
    "            batch_durations = np.array([duration.values])\n",
    "        else:\n",
    "            batch_durations, duration = padtoequalsize(batch_durations, duration, [-1,-2])\n",
    "            batch_durations = np.concatenate([batch_durations,[duration]],axis=0)\n",
    "    \n",
    "    if all_durations is None:\n",
    "        all_durations = np.array([batch_durations])\n",
    "    else:\n",
    "        all_durations,batch_durations = padtoequalsize(all_durations, batch_durations, [-1,-2,-3])\n",
    "        all_durations = np.concatenate([all_durations,[batch_durations]],axis=0)\n",
    "    \n",
    "        \n",
    "    #############\n",
    "    ### plots ###\n",
    "    #############\n",
    "    \n",
    "    if plot:\n",
    "        \"\"\"\n",
    "        transition_plot = vis.transition_plotter(fr_trans_norm.values, cluster_color, node_alpha=summary['duration_relative'].fillna(0).tolist())\n",
    "        plt.text(1.5, -1, f'{data_str}\\nN = {len(loc_trans)}', fontsize=12)\n",
    "        plt.title(f\"transitions of {data_str}\")\n",
    "        plt.savefig(os.path.join(outpath, f'{data_str}_batch_transitions.pdf'))\n",
    "        plt.show()\"\"\"\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        axs1 = fig.add_axes([0, .895, .2, .805])\n",
    "        axs1.axis('off')\n",
    "        dn = dendrogram(Z, orientation='left',ax= axs1)\n",
    "        axs2 = fig.add_axes([0.33, .9, .8, .8])\n",
    "        im = axs2.imshow(fr_transition_clust,norm=colors.PowerNorm(.4,vmax=1))#vmin=0,vmax=.2)#\n",
    "        axs2.set_xticks(range(len(cluster_group)))\n",
    "        axs2.set_xticklabels([cluster_group[k] for k in ordering], rotation=45,ha=\"center\")\n",
    "        axs2.set_yticks(range(len(cluster_group)))\n",
    "        axs2.set_yticklabels([cluster_group[k] for k in ordering])\n",
    "        cbar = axs2.figure.colorbar(im, ax=axs2)\n",
    "        cbar.ax.set_ylabel(\"X^0.4 normalization\", rotation=90, labelpad= 6)\n",
    "        axs2.set_title(f\"transitions of {data_str} per sec (x to y)\")\n",
    "        plt.savefig(os.path.join(outpath, f'{data_str}_batch_transitheatmap_clust.pdf'),bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "    \n",
    "        if WT_ordering:\n",
    "            fr_transition_WT = fr_trans_norm.iloc[WT_ordering,WT_ordering]\n",
    "            fig = plt.figure()\n",
    "            axs1 = fig.add_axes([0, .895, .2, .805])\n",
    "            axs1.axis('off')\n",
    "            #dn = dendrogram(Z, orientation='left',ax= axs1)\n",
    "            axs2 = fig.add_axes([0.33, .9, .8, .8])\n",
    "            im = axs2.imshow(fr_transition_WT,norm=colors.PowerNorm(.4,vmax=1))#vmin=0,vmax=.2)#\n",
    "            axs2.set_xticks(range(len(cluster_group)))\n",
    "            axs2.set_xticklabels([cluster_group[k] for k in WT_ordering], rotation=45,ha=\"center\")\n",
    "            axs2.set_yticks(range(len(cluster_group)))\n",
    "            axs2.set_yticklabels([cluster_group[k] for k in WT_ordering])\n",
    "            cbar = axs2.figure.colorbar(im, ax=axs2)\n",
    "            cbar.ax.set_ylabel(\"X^0.4 normalization\", rotation=90, labelpad= 6)\n",
    "            axs2.set_title(f\"transitions of {data_str} per sec (x to y)\")\n",
    "            plt.savefig(os.path.join(outpath, f'{data_str}_batch_transitheatmap_WTclust.pdf'),bbox_inches = \"tight\")\n",
    "            plt.show()\n",
    "        \n",
    "    \n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(2,5))\n",
    "        b = ax.barh(range(len(total_dur_rel)),total_dur_rel, color=list(cluster_color.values())[1:])\n",
    "        ax.set_yticks(range(len(cluster_group)-1))\n",
    "        ax.set_yticklabels([cluster_group[k] for k in cluster_group][1:])\n",
    "        ax.bar_label(b, label_type='edge', fmt='%.2g', padding=3)\n",
    "        ax.invert_yaxis()\n",
    "        plt.xlabel(f\"total rel. duration\")\n",
    "        plt.title(data_str)\n",
    "        plt.xlim(0,.6)\n",
    "        plt.savefig(os.path.join(outpath, f'{data_str}_batch_totaldur.pdf'),bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "    \n",
    "        # Calculate onoff sets\n",
    "        onoff = proc.onoff_dict(y_batch, labels =np.unique(y_batch_concat))\n",
    "    \n",
    "        fig = plt.figure(figsize=(.6*len(onoff.keys()),3), layout='constrained')\n",
    "        for k in onoff.keys():\n",
    "            if not np.isnan(k):\n",
    "                durs = pd.DataFrame(onoff[k])[1]/30\n",
    "                plt.boxplot(durs, positions=[k], widths=.5,sym='', patch_artist = True, boxprops={'facecolor':cluster_color[k]},medianprops={'color':'k'})\n",
    "        plt.xticks(range(len(cluster_group)-1),[cluster_group[k] for k in cluster_group][1:], rotation=45)\n",
    "        plt.ylabel(\"sec\")\n",
    "        plt.ylim(0,30)\n",
    "        plt.title(f\"duration of {data_str} (without fliers)\")\n",
    "        plt.savefig(os.path.join(outpath, f'{data_str}_batch_durboxplot.pdf'),bbox_inches = \"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca73a0d-443b-4b74-9143-f313252531da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_durations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3e1537-aaa3-48b6-9e56-7fb7042dd581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6958e3-3b1c-4df6-8df0-a1fd990ddd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1cabf-c47a-401a-b8a3-285c40b42e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_withnans_alignright(df_):\n",
    "    df = df_.copy()\n",
    "    for i in range(len(df.columns)):\n",
    "        nulls = df.iloc[np.where(df.iloc[:,i].notnull())[0][-1]+1:,i]\n",
    "        notnulls = df.iloc[:np.where(df.iloc[:,i].notnull())[0][-1],i]\n",
    "        right_aligned = pd.concat([nulls,notnulls], axis=0).reset_index(drop=True)\n",
    "        df.iloc[:,i] = right_aligned\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e006eda-6be7-4aa9-81fa-5518d789c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(96)\n",
    "bout_all = pd.DataFrame([])\n",
    "bout_pre_all = pd.DataFrame([])\n",
    "y_pre_all = pd.DataFrame([])\n",
    "bout_post_all = pd.DataFrame([])\n",
    "y_post_all = pd.DataFrame([])\n",
    "feat = 'velocity'\n",
    "cl = 1\n",
    "rdm_subset = np.random.choice(len(onoff[cl]), 100, replace=False)\n",
    "rdm_ons =[]\n",
    "for i,oo in enumerate(rdm_subset):\n",
    "    rdm_ons.append(onoff[cl][oo][0])\n",
    "    onset = onoff[cl][oo][0]\n",
    "    offset = onoff[cl][oo][0]+onoff[cl][oo][1]\n",
    "    bout = data_batch_concat.reset_index(drop=True)[onset:offset].reset_index(drop=True)\n",
    "    if all(bout[feat].isnull()):\n",
    "        print(i)\n",
    "        continue\n",
    "    bout_pre = data_batch_concat.reset_index(drop=True)[onset-60:onset].reset_index(drop=True)\n",
    "    bout_post = data_batch_concat.reset_index(drop=True)[offset:offset+60].reset_index(drop=True)\n",
    "    \n",
    "    bout_all = pd.concat([bout_all,bout[feat]], axis=1)\n",
    "\n",
    "    bout_pre_all = pd.concat([bout_pre_all,bout_pre[feat]], axis=1)\n",
    "    y_pre_all = pd.concat([y_pre_all,bout_pre['prediction']], axis=1)\n",
    "    bout_post_all = pd.concat([bout_post_all,bout_post[feat]], axis=1)\n",
    "    y_post_all = pd.concat([y_post_all,bout_post['prediction']], axis=1)\n",
    "\n",
    "bout_all.columns = list(range(len(bout_all.columns)))\n",
    "bout_pre_all.columns = list(range(len(bout_pre_all.columns)))\n",
    "y_pre_all.columns = list(range(len(y_pre_all.columns)))\n",
    "y_pre_color = y_pre_all[:150].replace(cluster_color)\n",
    "bout_post_all.columns = list(range(len(bout_post_all.columns)))\n",
    "y_post_all.columns = list(range(len(y_post_all.columns)))\n",
    "y_post_color = y_post_all[:150].replace(cluster_color)\n",
    "\n",
    "bout_all_right = df_withnans_alignright(bout_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e4158-0d21-4595-ac85-ec09628a9921",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "mask = data_batch_concat.prediction.isin([7])\n",
    "#fig = px.lines(bout_all, color = y_bout_all, width=800, height=400)\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "for trace in bout_all:\n",
    "    bout_ = bout_all[trace].iloc[:90].dropna().reset_index(drop=True)\n",
    "    bout_r_ = bout_all_right[trace].iloc[-90:].dropna().reset_index(drop=True)\n",
    "    pre_ = bout_pre_all[trace][y_pre_all[trace]==y_pre_all[trace].iloc[-1]].reset_index(drop=True)\n",
    "    post_ = bout_post_all[trace][y_post_all[trace]==y_post_all[trace].iloc[-1]].reset_index(drop=True)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(bout_)), y=bout_, line=dict(color=cluster_color[cl]),mode='lines'),\n",
    "                 row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(-len(pre_),0), y=pre_, line=dict(color=y_pre_color[trace].iloc[-1]),mode='lines'),\n",
    "                 row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(-len(bout_r_),0), y=bout_r_, line=dict(color=cluster_color[cl]),mode='lines'),\n",
    "                 row=1, col=2)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(post_)), y=post_, line=dict(color=y_post_color[trace].iloc[-1]),mode='lines'),\n",
    "                 row=1, col=2)\n",
    "\n",
    "    \n",
    "mean_ = pd.concat([bout_pre_all,bout_all],axis=0).reset_index(drop=True).mean(axis=1).iloc[:150]\n",
    "mean_r_ = pd.concat([bout_all_right, bout_post_all],axis=0).reset_index(drop=True).mean(axis=1).iloc[-150:]\n",
    "fig.add_trace(go.Scatter(x=np.arange(-60,90), y=mean_, line=dict(color='black',width=3),mode='lines'),\n",
    "                 row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=np.arange(-90,60), y=mean_r_, line=dict(color='black',width=3),mode='lines'),\n",
    "                 row=1, col=2)\n",
    "\n",
    "fig.add_vline(x=0, line=dict(color=\"Grey\",width=5))\n",
    "fig.update_xaxes(dtick=15, title=dict(text='Time [frames]'))\n",
    "fig.update_yaxes(range=[0, max(bout_all.max().max(),bout_pre_all.max().max(),bout_post_all.max().max())],title=dict(text=f'{feat}'))\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=500,\n",
    "    xaxis = dict(\n",
    "        tickmode = 'linear',\n",
    "        dtick = 15),\n",
    "    showlegend=False,\n",
    "    template='plotly_white',\n",
    "    title=dict(text=f\"Traces of {cluster_group[cl]} aligned at prediction onset (l) and offset (r)\", font=dict(size=16), x =.5, xanchor='center'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dbbba1-5f2c-4745-9917-f327189b7283",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([bout_pre_all,bout_all], axis=0).reset_index(drop=True)[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ddd09a-4b9b-4827-91ab-9e80261e0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onoff_ = pd.json_normalize(onoff).to_dict(orient='split')\n",
    "onoff_rev = {}\n",
    "for l,c in zip(onoff_['data'][0],onoff_['columns']):\n",
    "    for oo in l:\n",
    "        onoff_rev[oo[0]] = (c, oo[1])\n",
    "\n",
    "onoff_rev_df = pd.DataFrame(onoff_rev).T\n",
    "onoff_rev_df = onoff_rev_df.reindex(sorted(onoff_rev_df.index), axis=0)\n",
    "\n",
    "onoff_rev_dfidx = onoff_rev_df.index.to_series().reset_index(drop=True)\n",
    "prebout_idx = (onoff_rev_dfidx[onoff_rev_dfidx.isin(rdm_ons)].index - 1).tolist()\n",
    "\n",
    "prebout_c, prebout_dur, prebout = onoff_rev_df.iloc[prebout_idx,0],onoff_rev_df.iloc[prebout_idx,1], onoff_rev_df.index[prebout_idx].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f242b-35e0-4594-af30-ddcf25a7e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(8,5), sharey=True)\n",
    "axs[0].plot(range(0,90),bout_all[:90], c=cluster_color[cl],alpha=.7)\n",
    "for b,d,c in zip(prebout,prebout_dur,prebout_c):\n",
    "    axs[0].plot(range(-d if d < 60 else -60,0),data_batch_concat.reset_index(drop=True).iloc[b:b+d][feat][-d if d < 60 else -60:], c=cluster_color[c],alpha=.7)\n",
    "axs[0].plot(range(0,90),bout_all[:90].median(axis=1), c='#252422', linewidth=2)\n",
    "axs[0].axvline(0)\n",
    "axs[0].set_title(\"aligned beginning\")\n",
    "axs[1].plot(range(-90,0),bout_all_right[-90:], c=cluster_color[cl],alpha=.7)\n",
    "axs[1].plot(range(-90,0),bout_all_right[-90:].median(axis=1), c='#252422', linewidth=2)\n",
    "axs[1].axvline(0)\n",
    "axs[1].set_title(\"aligned end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfee0dc-6dfe-41d5-aaf2-dae30852b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_all[trace][y_pre_all[trace]==y_pre_all[trace].iloc[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97d24e-6c8e-4b5f-814a-7e5479d9dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "Z = linkage(fr_transition, 'single', optimal_ordering=True)\n",
    "ordering = np.concatenate((Z[::-1,0],Z[:,1]))\n",
    "ordering = ordering[ordering<=8]\n",
    "fr_trans_norm = (fr_transition/fr_transition.sum(axis=0)).fillna(0)\n",
    "fr_transition_clust = fr_transition.iloc[ordering,ordering]\n",
    "fr_trans_clust_norm = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea81f16-6c0b-42b1-b444-06f98925dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axs1 = fig.add_axes([0, .895, .2, .805])\n",
    "axs1.axis('off')\n",
    "dn = dendrogram(Z, orientation='left',ax= axs1)\n",
    "axs2 = fig.add_axes([0.33, .9, .8, .8])\n",
    "im = axs2.imshow(fr_transition_clust,norm=colors.PowerNorm(.4,vmax=1))#vmin=0,vmax=.2)#\n",
    "axs2.set_xticks(range(len(cluster_group)-1))\n",
    "axs2.set_xticklabels([cluster_group[k] for k in ordering], rotation=45,ha=\"center\")\n",
    "axs2.set_yticks(range(len(cluster_group)-1))\n",
    "axs2.set_yticklabels([cluster_group[k] for k in ordering])\n",
    "cbar = axs2.figure.colorbar(im, ax=axs2)\n",
    "cbar.ax.set_ylabel(\"X^0.4 normalization\", rotation=90, labelpad= 6)\n",
    "axs2.set_title(f\"transitions of {data_str} per sec (x to y)\")\n",
    "plt.savefig(os.path.join(out_predicted, os.path.basename(outpath)+'_batch_transitheatmap_clust.pdf'),bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1805f81-4486-477f-bd8c-2ed01661e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_trans_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0aeb5e-7094-4b85-9e08-bb9d92af84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2/.6*1,5))\n",
    "b = ax.barh(range(len(total_dur_rel)),total_dur_rel, color=list(cluster_color.values())[1:])\n",
    "ax.set_yticks(range(len(cluster_group)-1))\n",
    "ax.set_yticklabels([cluster_group[k] for k in cluster_group][1:])\n",
    "ax.bar_label(b, label_type='edge', fmt='%.2g', padding=3)\n",
    "ax.invert_yaxis()\n",
    "plt.xlabel(f\"total rel. duration\")\n",
    "plt.title(data_str)\n",
    "plt.xlim(0,1)\n",
    "plt.savefig(os.path.join(out_predicted, os.path.basename(outpath)+'_batch_totaldur.pdf'),bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a89a61-fad6-40ec-b19e-995d7aedf8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    data_describe = data_batch_concat.groupby(y_batch_concat).describe().T.loc[idx[:, ['mean','std','count']], :].sort_index(level=0).T\n",
    "    dur_describe = pd.DataFrame(dur, columns=['duration']).groupby(transi).describe().T.loc[idx[:, ['mean','std','count']], :].sort_index(level=0).T\n",
    "    dur_describe['duration','relative'] = pd.DataFrame(dur, columns=['duration']).groupby(transi).apply(lambda cd: cd.sum()/len(y_batch_concat))\n",
    "    summary = pd.concat([dur_describe, data_describe], axis=1)\n",
    "    summary.index.name = 'cluster'\n",
    "    summary = summary.T.reset_index(drop=True).set_index(summary.T.index.map('_'.join)).T\n",
    "    summary = summary.set_index(summary.index.astype(int))\n",
    "    summary = summary.reindex([k for k in cluster_label if k != -1])\n",
    "    summary.to_csv(os.path.join(out_predicted, os.path.basename(outpath)+'_batch_summary.csv'))\n",
    "\n",
    "    #### Older Version\n",
    "    \n",
    "    for i,d in enumerate(data_batch):\n",
    "        frame = d['prediction'].rolling(30).apply(lambda s: s.mode()[0])[29::30].values.flatten()\n",
    "        trans_col_,fr_transition_ = crosstab(frame[1:], frame[:-1], levels=([k for k in cluster_label if k != -1],[k for k in cluster_label if k != -1]))\n",
    "        #fr_transition_ = pd.read_csv() ##################################read transitions.csv should look like normal fr_transition, get trans_col from header\n",
    "        if i == 0:\n",
    "            fr_transition = fr_transition_\n",
    "            trans_col = trans_col_\n",
    "        if trans_col_ == trans_col:\n",
    "            fr_transition += fr_transition_\n",
    "        else:\n",
    "            print('WARNING')\n",
    "        #fr_transition/fr_transition.sum(axis=0)\n",
    "    \n",
    "    #othersum_axis0 = fr_transition.sum(axis=0)-fr_transition.diagonal()\n",
    "    #transition_toother = fr_transition/othersum_axis0\n",
    "    #transition_self = fr_transition.diagonal()/(othersum_axis0+fr_transition.diagonal())\n",
    "    #np.fill_diagonal(transition_toother, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5064a-1329-4204-9ca0-22c706704b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(load_data_from_keys(fpath, 'ethogram')).droplevel(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d336c61-9916-4728-a7e6-ed05e7751c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_from_keys(fpath, 'ethogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6006abd-fdec-4477-8570-1edf913550fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env2",
   "language": "python",
   "name": "sklearn-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

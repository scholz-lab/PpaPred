{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14b5538c-c780-4848-9d27-e2079b7f5f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.expanduser('~'))\n",
    "from PpaPy.helper.io import makedir\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', message='Mean of empty slice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25c803fd-dc10-49a4-b986-252cdd625662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NanConverter(json.JSONEncoder):\n",
    "    def nan2None(self, obj):\n",
    "        if isinstance(obj, dict):\n",
    "            return {k:self.nan2None(v) for k,v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [self.nan2None(v) for v in obj]\n",
    "        elif isinstance(obj, float) and np.isnan(obj):\n",
    "            return None\n",
    "        return obj\n",
    "    def encode(self, obj, *args, **kwargs):\n",
    "        return super().encode(self.nan2None(obj), *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d8244f9-91a7-4d6c-9acf-6ab35e1bdefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_keys(json_file, key):\n",
    "    def traverse_dict(d, key):\n",
    "        if isinstance(d, dict):\n",
    "            if key in d.keys():\n",
    "                return {key: d[key]}\n",
    "            else:\n",
    "                return {k: traverse_dict(v, key) for k, v in d.items()}\n",
    "        elif isinstance(d, list):\n",
    "            return [traverse_dict(x, key) for x in d]\n",
    "        else:\n",
    "            return d\n",
    "\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    nested_dict = traverse_dict(data, key)\n",
    "    return {(innerKey, outerKey): values for outerKey, innerDict in nested_dict.items() for innerKey, values in innerDict.items()} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18efb6f1-ab9d-4f9b-a4ec-50a1e27fd49c",
   "metadata": {},
   "source": [
    "Please provide where your files are stored and where you would like your data to be saved in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d0a3bd5-29bf-44e3-bbe5-231912f5022c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datestr = time.strftime(\"%Y%m%d-%HH%MM\")\n",
    "inpath = \"/gpfs/soma_fs/scratch/src/boeger/PpaPred_eren_35727184\" \n",
    "inpath = '/gpfs/soma_fs/scratch/src/boeger/PpaPred_roca_35727184'\n",
    "\n",
    "outpath = makedir(f\"/gpfs/soma_fs/home/boeger/PpaPred/{os.path.basename(inpath)}\")\n",
    "\n",
    "inpath_pattern = ['Exp2_WT_larvae', 'Exp2_tbh1_larvae','Exp2_tph1_larvae','Exp2_tdc1_larvae', 'Exp2_cat2_larvae']#\n",
    "inpath_pattern = ['Exp3_WT_larvae', \"Exp3_octr1_larvae\", \"Exp3_ser3_larvae\", \"Exp3_ser6_larvae\", \"Exp3_tyra2_larvae\", \"Exp3_ser2_larvae\", \"Exp3_lgc55_larvae\", \"Exp3_tyra3_larvae\", \"Exp3_tdc1_larvae\", \"Exp3_tbh1_larvae\", \"Exp3_tbh1tdc1_larvae\"]\n",
    "#inpath_pattern = ['Exp3_suppl_ser2tyra2tyra3_larvae']\n",
    "#inpath_pattern = ['Exp1_WT_larvae', 'Exp1_WT_OP50',]\n",
    "#inpath_pattern = ['Exp2_WT_larvae']\n",
    "inpath_pattern = [\"L147\", \"L157\", \"L176\", \"L118\", \"L119\", \"L156\"]#'L118','L147','L156',\n",
    "inpath_with_subfolders = True\n",
    "\n",
    "overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85c7a6a7-15ef-4994-a144-8bea8bf99f39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  6.41it/s]\n",
      "100%|██████████| 27/27 [00:06<00:00,  4.38it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  4.01it/s]\n",
      "100%|██████████| 47/47 [00:12<00:00,  3.84it/s]\n",
      "100%|██████████| 16/16 [00:05<00:00,  2.78it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  4.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for data_str in inpath_pattern:\n",
    "    ### I/O ################################################\n",
    "    pattern_dir = [os.path.join(root, name) for root, dirs, files in os.walk(inpath) for name in dirs if data_str in name][0]\n",
    "    all_files = [os.path.join(root, name) for root, dirs, files in os.walk(pattern_dir) for name in files if name.endswith('json') or name.endswith('csv') ]\n",
    "    loc_all = {os.path.basename(f):f for f in all_files if 'prediction.json' in f}\n",
    "    loc_summ = [f for f in all_files if 'summary.csv' in f]\n",
    "    loc_trans =  [f for f in all_files if 'transitions.csv' in f]\n",
    "    #loc_onoff = [f for f in all_files if 'onoff.json' in f]\n",
    "\n",
    "    if outpath is None:\n",
    "        outpath = os.path.commonpath(loc_all.values())\n",
    "    JsonOut = os.path.join(outpath,f'{data_str}_batch.json')\n",
    "\n",
    "    ### Load and save to batch json ##################################\n",
    "    for fn,fpath in tqdm.tqdm(loc_all.items()):\n",
    "        id = '_'.join(fn.split('_')[:-1])\n",
    "        data = pd.read_json(fpath, orient='split')\n",
    "        y = data['prediction']\n",
    "        if 8 in np.unique(y):\n",
    "            print(f\"Warning: {fn}\")\n",
    "    \n",
    "        proba = data.filter(regex='proba')\n",
    "        idx = proba.columns.str.split('_', expand=True)\n",
    "        proba.columns = idx\n",
    "        mean_probas = {cl:np.nanmean(proba.loc[:,('proba',cl)][y == eval(cl)]) for cl in proba.columns.levels[1]}\n",
    "        \n",
    "        summ_ = pd.read_csv([l for l in loc_summ if id in l][0])\n",
    "        \n",
    "        fr_transition_ = pd.read_csv([l for l in loc_trans if id in l][0], index_col=0)\n",
    "        fr_transition_[fr_transition_==0] = np.nan # for now until processing in FeedingPrediction is fixed\n",
    "        fr_transition_tuple = dict(zip(str(list(itertools.product(fr_transition_.columns.astype(int), fr_transition_.index))).strip('[()]').split('), ('), fr_transition_.values.T.flatten()))\n",
    "\n",
    "        data_mean = data[['velocity', 'rate', 'prediction']].groupby('prediction').mean().reindex(range(-1,8))\n",
    "        \n",
    "        # prep of json file structure\n",
    "        etho = {id:{'count':summ_.duration_count.fillna(0).to_dict(),\n",
    "                    'mean duration':summ_.duration_mean.to_dict(),\n",
    "                    'rel time in': summ_.duration_relative.fillna(0).to_dict(),\n",
    "                    'mean velocity': data_mean.velocity.to_dict(),\n",
    "                    'mean rate': data_mean.rate.to_dict(),\n",
    "                    'mean transitions':fr_transition_tuple,\n",
    "                    'mean prediction probability': mean_probas,\n",
    "                    'ethogram':y.to_list()}}\n",
    "        \n",
    "        # if file exists and overwrite is false\n",
    "        ow_org = overwrite\n",
    "        if os.path.isfile(JsonOut) and not overwrite:\n",
    "            with open(JsonOut, \"r\") as jsonfile:\n",
    "                batch = json.load(jsonfile)\n",
    "        else:\n",
    "            batch = {}\n",
    "            overwrite = False\n",
    "        \n",
    "        batch.update(etho)\n",
    "        jsnF = json.dumps(batch, indent = 4, cls=NanConverter)\n",
    "        with open(JsonOut, \"w\") as outfile:\n",
    "            outfile.write(jsnF)\n",
    "\n",
    "    overwrite = ow_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd7d926-dfab-4eda-ba03-e2b30289563a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env2",
   "language": "python",
   "name": "sklearn-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62be009-5b75-4f2c-8c69-3564ac300a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch, FancyArrowPatch\n",
    "import logging\n",
    "import yaml\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats.contingency import crosstab\n",
    "import networkx as nx\n",
    "from matplotlib.lines import Line2D\n",
    "import umap\n",
    "import itertools\n",
    "from sklearn.preprocessing import power_transform\n",
    "\n",
    "#home = os.path.expanduser(\"~\")\n",
    "sys.path.append(os.getcwd())\n",
    "from functions.load_model import load_tolist\n",
    "import functions.visualise as vis\n",
    "import functions.process as proc\n",
    "from functions.io import setup_logger, makedir\n",
    "from functions import FeatureEngine\n",
    "sys.path.append(os.path.expanduser('~'))\n",
    "from PpaPy.processing.preprocess import addhistory, select_features\n",
    "from functions.modelfunctions import add_power_transform, select_features, addhistory\n",
    "import argparse\n",
    "\n",
    "import pickle\n",
    "from sklearn import set_config\n",
    " \n",
    "from numba import jit\n",
    "# set invalid (division by zero error) to ignore\n",
    "np.seterr(invalid='ignore')\n",
    "\n",
    "\n",
    "class NpIntEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "class NanConverter(json.JSONEncoder):\n",
    "    def nan2None(self, obj):\n",
    "        if isinstance(obj, dict):\n",
    "            return {k:self.nan2None(v) for k,v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [self.nan2None(v) for v in obj]\n",
    "        elif isinstance(obj, float) and np.isnan(obj):\n",
    "            return None\n",
    "        return obj\n",
    "    def encode(self, obj, *args, **kwargs):\n",
    "        return super().encode(self.nan2None(obj), *args, **kwargs)\n",
    "    \n",
    "# %% [markdown]\n",
    "# Please provide where your files are stored and where you would like your data to be saved in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29521f07-e577-49de-a7c6-45e44b5d876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "inpath = \"/gpfs/soma_fs/scratch/src/boeger/data_gueniz/\"\n",
    "inpath_with_subfolders = True\n",
    "inpath_pattern = [\"Exp1_WT_OP50\"]\n",
    "args_out = \"/gpfs/soma_fs/scratch/src/boeger/PpaPred_eren_35727184\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64da8fc1-d62b-4a23-b45c-9a2b8b57a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_outpath = makedir(args_out)\n",
    "\n",
    "# %%\n",
    "date = time.strftime(\"%Y%m%d\")\n",
    "datestr = time.strftime(\"%Y%m%d-%HH%MM\")\n",
    "home = os.path.expanduser(\"~\")\n",
    "\n",
    "if inpath_with_subfolders:\n",
    "    new_inpath = [os.path.join(inpath, sub) for sub in os.listdir(inpath) if any(pat in sub for pat in inpath_pattern)]\n",
    "    inpath = new_inpath\n",
    "else:\n",
    "    inpath = [inpath]\n",
    "\n",
    "outpath = []\n",
    "for p in inpath:\n",
    "    in_folder = os.path.basename(p)\n",
    "    outpath.append(makedir(os.path.abspath(f\"{base_outpath}/{in_folder}\")))\n",
    "\n",
    "\n",
    "# %%\n",
    "# In the following section, standard model parameters are set. Change those only if necessary.\n",
    "# changes to config file are preferrerable\n",
    "config = yaml.safe_load(open(\"config.yml\", \"r\"))\n",
    "\n",
    "cluster_color = config['cluster_color']\n",
    "cluster_group = config['cluster_group_man']\n",
    "cluster_label = config['cluster_names']\n",
    "clu_group_label = {_:f'{_}, {__}' for _, __ in tuple(zip([c for c in cluster_label.values()],[g for g in cluster_group.values()]))}\n",
    "skip_already = config['settings']['skip_already']\n",
    "overwrite = True\n",
    "\n",
    "model_path = config['settings']['model']\n",
    "version = os.path.basename(model_path).split(\"_\")[1].split(\".\")[0]\n",
    "ASpath = config['settings']['ASpath']\n",
    "smooth = config['settings']['fbfill']\n",
    "fps = config['settings']['fps']\n",
    "\n",
    "# lists to store already processed files in\n",
    "prediction_done = []\n",
    "\n",
    "# %% [markdown]\n",
    "# 1. Feature Engineering\n",
    "# In the following section, additional features are calculated.\n",
    "# The engineerd data files are saved under the specified outpath/subfolder.\n",
    "# (with subfolder being the inpath folder name postfixed by _engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca0f19-bab2-45f9-ba87-164d3b0122f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874081a9-87cb-4a40-8976-5c3cb457398f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XYs, CLines  = FeatureEngine.run(inpath, outpath, return_XYCLine =True, skip_engine = False, skip_already=False, out_fn_suffix='prediction') # skip_engine skip_already\n",
    "\n",
    "# %%\n",
    "\n",
    "set_config(transform_output=\"pandas\")\n",
    "model = joblib.load(open(model_path, 'rb'))\n",
    "augsel = joblib.load(ASpath)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# %%\n",
    "all_engine = [os.path.join(root, name) for root, dirs, files in os.walk(base_outpath) for name in files if any(pat in os.path.basename(root) for pat in inpath_pattern)]\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112f463-c13a-4524-a734-2301653495b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "for fpath in tqdm.tqdm(all_engine):\n",
    "    fn = os.path.basename(fpath)\n",
    "    dir_engine = os.path.dirname(fpath)\n",
    "    if skip_already and fn in os.listdir(outpath):\n",
    "        continue\n",
    "    if not fn[0] == '.' and not fn in prediction_done and os.path.isfile(fpath):\n",
    "        print(fn)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6dae5d-2480-4e1d-a9a9-c107e8f4cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_tolist(fpath, droplabelcol=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351efe59-8640-47bd-9f1b-d93b7275cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = augsel.fit_transform(d)\n",
    "X = imp.fit_transform(X) # model seems to run well without\n",
    "#X = X.add_suffix('_tr') # not longer needed once new model has been trained\n",
    "\n",
    "pred = model.predict(X)\n",
    "proba = model.predict_proba(X)\n",
    "\n",
    "proba_max = np.amax(proba, axis=1) ### New\n",
    "proba_max_mean = pd.DataFrame(proba_max).rolling(30, min_periods=1).mean().values ### New\n",
    "proba_low50 = np.all(proba_max_mean < .5, axis=1) ### New\n",
    "pred[proba_low50] = -1 ### NEW\n",
    "pred = pd.Series(pred, index=X.index, name='prediction').reindex(d.index, method='bfill', limit=29).fillna(-1) ### NEW\n",
    "proba = pd.DataFrame(proba, index=X.index, columns=[f'proba_{i}' for i in range(proba.shape[1])]).reindex(d.index, method='bfill', limit=29).fillna(0)\n",
    "\n",
    "p_out = pd.concat([d, pred, proba], axis=1) #d, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57094ae6-8dd3-4656-8928-38034787ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb35925-e32b-4ee5-b8e5-88664a95b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(fpath):\n",
    "    with open(fpath, \"r\") as jsonfile:\n",
    "        recording = json.load(jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2807fb-e4a8-4c26-9e60-5b727ca7a509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df14883-9648-4398-ab0b-9a2ca3013594",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording.update(p_out.to_dict())\n",
    "jsnF = json.dumps(recording, indent = 4, cls=NanConverter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ac5f6-f0e9-4d18-8257-9869d1df652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fpath, \"w\") as outfile:\n",
    "    outfile.write(jsnF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e5fcd6-b593-4aca-91d1-2139c5a5fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_out.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3194dcb-a2b3-43c6-ba36-aad072a1e0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env2",
   "language": "python",
   "name": "sklearn-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
